{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF Vectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "57PRHGvgI7cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('/content/Hotel_Reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_QA33h0JAeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Average_Score'].unique()\n",
        "df[\"Average_Score_Round\"] = df[\"Average_Score\"].apply(lambda x: int(round(x)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUi9o2jGJDjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_reviews(row):\n",
        "  review = row['Average_Score_Round']\n",
        "  if(review == 6 and review == 5):\n",
        "    return 1\n",
        "  if(review == 7):\n",
        "    return 2\n",
        "  if(review == 8):\n",
        "     return 3\n",
        "  if(review == 9):\n",
        "    return 4\n",
        "  else:\n",
        "      return 5\n",
        "\n",
        "\n",
        "def createLabelsFromReviewPoints(df):\n",
        "  df['Target']= df.apply (lambda row: label_reviews(row), axis=1)\n",
        "  return df\n",
        "  \n",
        "df = createLabelsFromReviewPoints(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isordev1JLHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df.sample(n = 160000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOiFEg_QQMLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1[\"Review\"] = df1[\"Negative_Review\"] + df1[\"Positive_Review\"]\n",
        "#df1['Target'] = np.where(df1.eval(\"Average_Score_Round > 8\"), \"Good\", \"Bad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsTrtkdVJPF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = df1[['Review','Target','Negative_Review','Positive_Review']]# remove 'No Negative' or 'No Positive' from text\n",
        "df_final[\"Negative_Review\"] = df_final[\"Negative_Review\"].apply(lambda x: x.replace(\"No Negative\", \"\"))\n",
        "df_final[\"Positive_Review\"] = df_final[\"Positive_Review\"].apply(lambda x: x.replace(\"No Positive\", \"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb290Q9k0wnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE3hjWqL0tIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPACgi-D01Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsBDXFF_05S5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "464d5c7e-cffc-4089-bdc1-d7d7fa2dcb5f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHyIKy030-em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df[\"review_clean\"] = df[\"Review\"].apply(lambda x: clean_text(x))\n",
        "df_final['Review'] = df_final['Review'].apply(lambda text: clean_text(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK7jQoi9JdVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the data to train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df_final[\"Review\"]\n",
        "y = df_final[\"Target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1hAP04CJfqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1d509465-28fa-4f6f-c4cf-72f4f7927a85"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlObC83mJo6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect_1 = TfidfVectorizer(min_df = 1, stop_words={'english'}, max_features = 8000,\n",
        "                          ngram_range=(1,3)).fit(X_train)\n",
        "X_train1 = vect_1.transform(X_train)\n",
        "X_test1 = vect_1.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q98Z4DDQJrc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df_words = pd.DataFrame(columns=vect_1.get_feature_names(), data=X_train1.toarray())\n",
        "new_df_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IZNSMXbB7Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#counting most repetitive words \n",
        "word_counts = np.array(np.sum(X_train1, axis=0)).reshape((-1,))\n",
        "words = np.array(vect_1.get_feature_names())\n",
        "words_df = pd.DataFrame({\"word\":words, \"count\":word_counts})\n",
        "words_df.sort_values(by=\"count\",ascending=False).tail(50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC86taPXvEaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing in the form of Word Cloud\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "text_pos = \" \".join(i for i in words_df.word)\n",
        "wc_pos = WordCloud(background_color=\"black\", max_words=1000, contour_width=14, contour_color='firebrick')\n",
        "\n",
        "# Generate a wordcloud\n",
        "wc_pos.generate(text_pos)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(wc_pos, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VALaYPqg5nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fitting a logistic regression model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import ensemble, linear_model, neighbors, svm, tree\n",
        "from sklearn import svm, model_selection, tree, linear_model, neighbors, naive_bayes, ensemble\n",
        "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWYG8NIztfrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting Logistic regression to the training set\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "logreg1 = LogisticRegressionCV()\n",
        "logreg1.fit(X_train1, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_logreg = logreg1.predict(X_test1)\n",
        "\n",
        "pred_prob = logreg1.predict_proba(X_test1\n",
        "                                  \n",
        "\n",
        "# Confusion matrix and classifacation report for Logistic Regression \n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_lr = confusion_matrix(y_test, y_pred_logreg)\n",
        "df_cm_lr = pd.DataFrame(con_mat_lr, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "#display(con_mat_lr)\n",
        "plt.figure(figsize=(10,6))\n",
        "conf_mat_normalized = df_cm_lr.astype('float') / df_cm_lr.sum(axis=1)[:, np.newaxis]\n",
        "sns.heatmap(df_cm_lr, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, y_pred_logreg, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ucq8Dhot3Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Support Vector Classifier\n",
        "from sklearn.svm import LinearSVC\n",
        "svc = LinearSVC()\n",
        "svc.fit(X_train1, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_svc = svc.predict(X_test1)\n",
        "\n",
        "# Loading COnfusion matrix and classifaction report \n",
        "print('The Confusion Matrix')\n",
        "con_mat_svc = confusion_matrix(y_test, y_pred_svc)\n",
        "#df_cm_svc = pd.DataFrame(con_mat_svc, columns = ['Predicted 0','Predicted 1'], index = ['True 0','True 1'])\n",
        "display(con_mat_svc)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_svc = confusion_matrix(y_test, y_pred_svc)\n",
        "df_cm_svc = pd.DataFrame(con_mat_svc, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "#display(con_mat_lr)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_cm_svc, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, y_pred_svc, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHiGn2vtuDb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building Multinomial Naive Bayes modle and fit it to our training set\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier1 = MultinomialNB(alpha=0.1)\n",
        "classifier1.fit(X_train1, y_train)\n",
        "pred = classifier1.predict(X_test)\n",
        "\n",
        "\n",
        "# Confusion matrix and classifacation report for Multinomial Navie Bayes\n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_mb = confusion_matrix(y_test, pred)\n",
        "#df_cm_lr = pd.DataFrame(con_mat_lr, columns = ['Predicted 0','Predicted 1'], index = ['True 0','True 1'])\n",
        "display(con_mat_mb)\n",
        "\n",
        "df_cm_mb = pd.DataFrame(con_mat_mb, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_cm_mb, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, pred, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jBrNXI-uOc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Random Forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=10,random_state=1)\n",
        "rf.fit(X_train1, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_rf = rf.predict(X_test1)\n",
        "\n",
        "\n",
        "\n",
        "# Confusion matrix and classifacation report for Random Forest classifier\n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "#df_cm_lr = pd.DataFrame(con_mat_lr, columns = ['Predicted 2','Predicted 3' ], index = ['True 0','True 1'])\n",
        "display(con_mat_rf)\n",
        "\n",
        "df_cm_lr = pd.DataFrame(con_mat_rf, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_cm_lr, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_repor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSK9a6oft1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performance comparsion using Machine learning algorithms \n",
        "MLA = [\n",
        "       linear_model.LogisticRegressionCV(),\n",
        "       naive_bayes.MultinomialNB(),\n",
        "       svm.LinearSVC(),\n",
        "       ensemble.RandomForestClassifier(),  \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pefDML0jh2vf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "332c07aa-75c9-472c-91fe-ed9e6553ce53"
      },
      "source": [
        "# Training the data into model and calculating performance \n",
        "MLA_columns = []\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "row_index = 0\n",
        "for alg in MLA:\n",
        "  predicted = alg.fit(X_train1, y_train).predict(X_test1)\n",
        "  MLA_name = alg.__class__.__name__\n",
        "  MLA_compare.loc[row_index,'MLA Name'] = MLA_name\n",
        "  MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(alg.score(X_train1, y_train), 4)\n",
        "  MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round(alg.score(X_test1, y_test), 4)\n",
        "  MLA_compare.loc[row_index, 'MLA Precission'] = precision_score(y_test, predicted,average='weighted')\n",
        "  MLA_compare.loc[row_index, 'MLA Recall'] = recall_score(y_test, predicted,average='weighted')\n",
        "  row_index+=1\n",
        "    \n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)    \n",
        "MLA_compare\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLA Name</th>\n",
              "      <th>MLA Train Accuracy</th>\n",
              "      <th>MLA Test Accuracy</th>\n",
              "      <th>MLA Precission</th>\n",
              "      <th>MLA Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegressionCV</td>\n",
              "      <td>0.6627</td>\n",
              "      <td>0.6006</td>\n",
              "      <td>0.616424</td>\n",
              "      <td>0.6006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>0.6271</td>\n",
              "      <td>0.5946</td>\n",
              "      <td>0.559434</td>\n",
              "      <td>0.5946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.9886</td>\n",
              "      <td>0.5820</td>\n",
              "      <td>0.555045</td>\n",
              "      <td>0.5820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>0.7091</td>\n",
              "      <td>0.5713</td>\n",
              "      <td>0.550813</td>\n",
              "      <td>0.5713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 MLA Name  MLA Train Accuracy  ...  MLA Precission  MLA Recall\n",
              "0    LogisticRegressionCV              0.6627  ...        0.616424      0.6006\n",
              "1           MultinomialNB              0.6271  ...        0.559434      0.5946\n",
              "3  RandomForestClassifier              0.9886  ...        0.555045      0.5820\n",
              "2               LinearSVC              0.7091  ...        0.550813      0.5713\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmU-JvL4iUzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "sns.barplot(x=\"MLA Name\", y=\"MLA Train Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('MLA Train Accuracy Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oKVMFDcioJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "sns.barplot(x=\"MLA Name\", y=\"MLA Test Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('MLA Test Accuracy Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7exaVREjGaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = pd.DataFrame(y_pred_logreg, columns=['Pred_Rating']).to_csv('prediction.csv')\n",
        "df3 = pd.read_csv('/content/prediction (1).csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUGyeEXRk-_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"Star3\",\"Star2\",\"Star4\"]\n",
        "df3.Pred_Rating.value_counts().plot.pie(autopct='%1.1f%%',figsize=(8,10));\n",
        "plt.legend(title=\"Ratings\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}