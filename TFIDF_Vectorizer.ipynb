{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF_Vectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "57PRHGvgI7cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('/content/Hotel_Reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_QA33h0JAeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Average_Score'].unique()\n",
        "df[\"Average_Score_Round\"] = df[\"Average_Score\"].apply(lambda x: int(round(x)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUi9o2jGJDjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_reviews(row):\n",
        "  review = row['Average_Score_Round']\n",
        "  if(review == 6 and review == 5):\n",
        "    return 1\n",
        "  if(review == 7):\n",
        "    return 2\n",
        "  if(review == 8):\n",
        "     return 3\n",
        "  if(review == 9):\n",
        "    return 4\n",
        "  else:\n",
        "      return 5\n",
        "\n",
        "\n",
        "def createLabelsFromReviewPoints(df):\n",
        "  df['Target']= df.apply (lambda row: label_reviews(row), axis=1)\n",
        "  return df\n",
        "  \n",
        "df = createLabelsFromReviewPoints(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isordev1JLHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df.sample(n = 160000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOiFEg_QQMLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1[\"Review\"] = df1[\"Negative_Review\"] + df1[\"Positive_Review\"]\n",
        "#df1['Target'] = np.where(df1.eval(\"Average_Score_Round > 8\"), \"Good\", \"Bad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsTrtkdVJPF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = df1[['Review','Target','Negative_Review','Positive_Review']]# remove 'No Negative' or 'No Positive' from text\n",
        "df_final[\"Negative_Review\"] = df_final[\"Negative_Review\"].apply(lambda x: x.replace(\"No Negative\", \"\"))\n",
        "df_final[\"Positive_Review\"] = df_final[\"Positive_Review\"].apply(lambda x: x.replace(\"No Positive\", \"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb290Q9k0wnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE3hjWqL0tIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPACgi-D01Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsBDXFF_05S5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "464d5c7e-cffc-4089-bdc1-d7d7fa2dcb5f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHyIKy030-em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df[\"review_clean\"] = df[\"Review\"].apply(lambda x: clean_text(x))\n",
        "df_final['Review'] = df_final['Review'].apply(lambda text: clean_text(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK7jQoi9JdVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the data to train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df_final[\"Review\"]\n",
        "y = df_final[\"Target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1hAP04CJfqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1d509465-28fa-4f6f-c4cf-72f4f7927a85"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlObC83mJo6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect_1 = TfidfVectorizer(min_df = 1, stop_words={'english'}, max_features = 8000,\n",
        "                          ngram_range=(1,3)).fit(X_train)\n",
        "X_train1 = vect_1.transform(X_train)\n",
        "X_test1 = vect_1.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q98Z4DDQJrc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df_words = pd.DataFrame(columns=vect_1.get_feature_names(), data=X_train1.toarray())\n",
        "new_df_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IZNSMXbB7Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#counting most repetitive words \n",
        "word_counts = np.array(np.sum(X_train1, axis=0)).reshape((-1,))\n",
        "words = np.array(vect_1.get_feature_names())\n",
        "words_df = pd.DataFrame({\"word\":words, \"count\":word_counts})\n",
        "words_df.sort_values(by=\"count\",ascending=False).tail(50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC86taPXvEaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing in the form of Word Cloud\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "text_pos = \" \".join(i for i in words_df.word)\n",
        "wc_pos = WordCloud(background_color=\"black\", max_words=1000, contour_width=14, contour_color='firebrick')\n",
        "\n",
        "# Generate a wordcloud\n",
        "wc_pos.generate(text_pos)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(wc_pos, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VALaYPqg5nJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fitting a logistic regression model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import ensemble, linear_model, neighbors, svm, tree\n",
        "from sklearn import svm, model_selection, tree, linear_model, neighbors, naive_bayes, ensemble\n",
        "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWYG8NIztfrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting Logistic regression to the training set\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "logreg1 = LogisticRegressionCV()\n",
        "logreg1.fit(X_train1, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_logreg = logreg1.predict(X_test1)\n",
        "\n",
        "pred_prob = logreg1.predict_proba(X_test1\n",
        "                                  \n",
        "\n",
        "# Confusion matrix and classifacation report for Logistic Regression \n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_lr = confusion_matrix(y_test, y_pred_logreg)\n",
        "df_cm_lr = pd.DataFrame(con_mat_lr, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "#display(con_mat_lr)\n",
        "plt.figure(figsize=(10,6))\n",
        "conf_mat_normalized = df_cm_lr.astype('float') / df_cm_lr.sum(axis=1)[:, np.newaxis]\n",
        "sns.heatmap(df_cm_lr, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, y_pred_logreg, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ucq8Dhot3Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Support Vector Classifier\n",
        "from sklearn.svm import LinearSVC\n",
        "svc = LinearSVC()\n",
        "svc.fit(X_train1, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_svc = svc.predict(X_test1)\n",
        "\n",
        "# Loading COnfusion matrix and classifaction report \n",
        "print('The Confusion Matrix')\n",
        "con_mat_svc = confusion_matrix(y_test, y_pred_svc)\n",
        "#df_cm_svc = pd.DataFrame(con_mat_svc, columns = ['Predicted 0','Predicted 1'], index = ['True 0','True 1'])\n",
        "display(con_mat_svc)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_svc = confusion_matrix(y_test, y_pred_svc)\n",
        "df_cm_svc = pd.DataFrame(con_mat_svc, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "#display(con_mat_lr)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_cm_svc, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, y_pred_svc, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHiGn2vtuDb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building Multinomial Naive Bayes modle and fit it to our training set\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier1 = MultinomialNB(alpha=0.1)\n",
        "classifier1.fit(X_train1, y_train)\n",
        "pred = classifier1.predict(X_test)\n",
        "\n",
        "\n",
        "# Confusion matrix and classifacation report for Multinomial Navie Bayes\n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_mb = confusion_matrix(y_test, pred)\n",
        "#df_cm_lr = pd.DataFrame(con_mat_lr, columns = ['Predicted 0','Predicted 1'], index = ['True 0','True 1'])\n",
        "display(con_mat_mb)\n",
        "\n",
        "df_cm_mb = pd.DataFrame(con_mat_mb, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_cm_mb, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, pred, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jBrNXI-uOc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Random Forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=10,random_state=1)\n",
        "rf.fit(X_train1, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_rf = rf.predict(X_test1)\n",
        "\n",
        "\n",
        "\n",
        "# Confusion matrix and classifacation report for Random Forest classifier\n",
        "from sklearn.metrics import classification_report\n",
        "print('The Confusion Matrix')\n",
        "con_mat_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "#df_cm_lr = pd.DataFrame(con_mat_lr, columns = ['Predicted 2','Predicted 3' ], index = ['True 0','True 1'])\n",
        "display(con_mat_rf)\n",
        "\n",
        "df_cm_lr = pd.DataFrame(con_mat_rf, index = ['Star2','Star3','Star4',\"Star5\"], \n",
        "                   columns = ['Star2','Star3','Star4',\"Star5\"])\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_cm_lr, annot=True,fmt='.1f')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show(block = False)\n",
        "\n",
        "print('The Classification report')\n",
        "report = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "df_repor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSK9a6oft1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performance comparsion using Machine learning algorithms \n",
        "MLA = [\n",
        "       linear_model.LogisticRegressionCV(),\n",
        "       naive_bayes.MultinomialNB(),\n",
        "       svm.LinearSVC(),\n",
        "       ensemble.RandomForestClassifier(),  \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pefDML0jh2vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the data into model and calculating performance \n",
        "MLA_columns = []\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "row_index = 0\n",
        "for alg in MLA:\n",
        "  predicted = alg.fit(X_train1, y_train).predict(X_test1)\n",
        "  MLA_name = alg.__class__.__name__\n",
        "  MLA_compare.loc[row_index,'MLA Name'] = MLA_name\n",
        "  MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(alg.score(X_train1, y_train), 4)\n",
        "  MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round(alg.score(X_test1, y_test), 4)\n",
        "  MLA_compare.loc[row_index, 'MLA Precission'] = precision_score(y_test, predicted,average='weighted')\n",
        "  MLA_compare.loc[row_index, 'MLA Recall'] = recall_score(y_test, predicted,average='weighted')\n",
        "  row_index+=1\n",
        "    \n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)    \n",
        "MLA_compare\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmU-JvL4iUzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "sns.barplot(x=\"MLA Name\", y=\"MLA Train Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('MLA Train Accuracy Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oKVMFDcioJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "sns.barplot(x=\"MLA Name\", y=\"MLA Test Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('MLA Test Accuracy Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7exaVREjGaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = pd.DataFrame(y_pred_logreg, columns=['Pred_Rating']).to_csv('prediction.csv')\n",
        "df3 = pd.read_csv('/content/prediction (1).csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUGyeEXRk-_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"Star3\",\"Star2\",\"Star4\"]\n",
        "df3.Pred_Rating.value_counts().plot.pie(autopct='%1.1f%%',figsize=(8,10));\n",
        "plt.legend(title=\"Ratings\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}