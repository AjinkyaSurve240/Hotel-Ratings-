{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAshing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "57PRHGvgI7cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/Hotel_Reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_QA33h0JAeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Average_Score'].unique()\n",
        "df[\"Average_Score_Round\"] = df[\"Average_Score\"].apply(lambda x: int(round(x)))\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUi9o2jGJDjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_reviews(row):\n",
        "  review = row['Average_Score_Round']\n",
        "  if(review == 6 and review == 5):\n",
        "    return 1\n",
        "  if(review == 7):\n",
        "    return 2\n",
        "  if(review == 8):\n",
        "     return 3\n",
        "  if(review == 9):\n",
        "    return 4\n",
        "  else:\n",
        "      return 5\n",
        "\n",
        "\n",
        "def createLabelsFromReviewPoints(df):\n",
        "  df['Target']= df.apply (lambda row: label_reviews(row), axis=1)\n",
        "  return df\n",
        "  \n",
        "df = createLabelsFromReviewPoints(df)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isordev1JLHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df.sample(n = 160000) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOiFEg_QQMLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1[\"Review\"] = df1[\"Negative_Review\"] + df1[\"Positive_Review\"]\n",
        "#df1['Target'] = np.where(df1.eval(\"Average_Score_Round > 8\"), \"Good\", \"Bad\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsTrtkdVJPF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = df1[['Review','Target','Negative_Review','Positive_Review']]# remove 'No Negative' or 'No Positive' from text\n",
        "df_final[\"Negative_Review\"] = df_final[\"Negative_Review\"].apply(lambda x: x.replace(\"No Negative\", \"\"))\n",
        "df_final[\"Positive_Review\"] = df_final[\"Positive_Review\"].apply(lambda x: x.replace(\"No Positive\", \"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb290Q9k0wnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE3hjWqL0tIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPACgi-D01Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    text = [x for x in text if x not in stop]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsBDXFF_05S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHyIKy030-em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df[\"review_clean\"] = df[\"Review\"].apply(lambda x: clean_text(x))\n",
        "df_final['Review'] = df_final['Review'].apply(lambda text: clean_text(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK7jQoi9JdVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the data to train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df_final[\"Review\"]\n",
        "y = df_final[\"Target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlObC83mJo6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "has_vec = HashingVectorizer(tokenizer = my_tokenizer,stop_words={'english'},\n",
        "                            ngram_range= (1,3),alternate_sign=False,strip_accents='unicode',n_features=8000).fit(X_train)\n",
        "\n",
        "train_hash = has_vec.transform(X_train)\n",
        "test_hash = has_vec.transform(X_test)\n",
        "\n",
        "\n",
        "Hash_words = pd.DataFrame(train_hash.toarray())"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VALaYPqg5nJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b02798f9-495c-48f1-c8e3-0dfc1823e71a"
      },
      "source": [
        "# fitting a logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Fitting Logistic regression to the training set\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_hash, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_logreg = logreg.predict(test_hash))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 60.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Aut_NvDwCt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "svc = LinearSVC(multi_class='ovr')\n",
        "svc.fit(train_hash, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_svc = svc.predict(test_hash)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O60Awdcgcfcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building Multinomial Naive Bayes modle and fit it to our training set\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier1 = MultinomialNB()\n",
        "classifier1.fit(train_hash, y_train)\n",
        "pred = classifier1.predict(test_hash)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzi2zUugeJ0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=5,random_state=1)\n",
        "rf.fit(train_hash, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred_rf = rf.predict(test_hash)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSK9a6oft1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\n",
        "from sklearn import svm, model_selection, tree, linear_model, neighbors, naive_bayes, ensemble\n",
        "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n",
        "MLA = [\n",
        "       linear_model.LogisticRegressionCV(),\n",
        "       #Navies Bayes\n",
        "       naive_bayes.MultinomialNB(),\n",
        "       svm.LinearSVC(),\n",
        "       ensemble.RandomForestClassifier(),  \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pefDML0jh2vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MLA_columns = []\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "row_index = 0\n",
        "for alg in MLA:\n",
        "  predicted = alg.fit(train_hash, y_train).predict(test_hash)\n",
        "  MLA_name = alg.__class__.__name__\n",
        "  MLA_compare.loc[row_index,'MLA Name'] = MLA_name\n",
        "  MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(alg.score(train_hash, y_train), 4)\n",
        "  MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round(alg.score(test_hash, y_test), 4)\n",
        "  MLA_compare.loc[row_index, 'MLA Precission'] = precision_score(y_test, predicted,average='weighted')\n",
        "  MLA_compare.loc[row_index, 'MLA Recall'] = recall_score(y_test, predicted,average='weighted')\n",
        "  row_index+=1\n",
        "    \n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)    \n",
        "MLA_compare\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3FvjTv9wnCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "sns.barplot(x=\"MLA Name\", y=\"MLA Train Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('MLA Train Accuracy Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5TdKFRJwpjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize=(12,6))\n",
        "sns.barplot(x=\"MLA Name\", y=\"MLA Test Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n",
        "plt.xticks(rotation=50)\n",
        "plt.title('MLA Test Accuracy Comparison')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}